{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":5065,"status":"ok","timestamp":1733294305695,"user":{"displayName":"Marien Manima","userId":"08622047204238479683"},"user_tz":480},"id":"ZDTDzSU6Lxe9"},"outputs":[],"source":["import numpy as np\n","import cv2\n","import os\n","import random\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import numpy as np\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,Dense,Activation\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":435,"status":"ok","timestamp":1733294312363,"user":{"displayName":"Marien Manima","userId":"08622047204238479683"},"user_tz":480},"id":"tmsF7D8Ca5hT"},"outputs":[],"source":["\n","\n","\n","def traiterImage (image_path):\n","  # Charger l'image et la redimensionner\n","  image = Image.open(image_path)\n","  image = image.resize((100, 100))\n","\n","  image_array = np.array(image)\n","\n","  # Vérifier la forme\n","  print(image_array.shape)\n","\n","  return image_array/255\n","\n","\n","\n","def transformationImageEnTableau(principale,sousDossier,data):\n","\n","\n","  for categories in sousDossier:\n","      folder=os.path.join(principale,categories)\n","      print(folder)\n","      label=sousDossier.index(categories)\n","\n","\n","      for img in os.listdir(folder):\n","          img=os.path.join(folder,img)\n","          img_arr=cv2.imread(img)\n","          if img_arr is not None:  # Check if the image is successfully loaded\n","              img_arr = cv2.resize(img_arr, (100, 100))\n","              data.append([img_arr, label])\n","          else:\n","              print(f\"Failed to load image {img}\")\n","  return data\n","\n","\n","\n","\n","\n","\n","def find_Class(directory_path):\n","    if not os.path.exists(directory_path):\n","        raise ValueError(f\"The directory '{directory_path}' does not exist.\")\n","    if not os.path.isdir(directory_path):\n","        raise ValueError(f\"The path '{directory_path}' is not a directory.\")\n","\n","    # Get a list of all entries in the directory\n","    all_entries = os.listdir(directory_path)\n","\n","    # Filter out only directories\n","    folders = [entry for entry in all_entries if os.path.isdir(os.path.join(directory_path, entry))]\n","\n","    return folders"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33026,"status":"ok","timestamp":1733294353915,"user":{"displayName":"Marien Manima","userId":"08622047204238479683"},"user_tz":480},"id":"S4NRCLtmb14k","outputId":"a524ec91-d241-4817-f0ca-d52fe1738e89"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /ressources\n"]}],"source":["from google.colab import drive\n","drive.mount('/ressources')\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":911,"status":"ok","timestamp":1733294364481,"user":{"displayName":"Marien Manima","userId":"08622047204238479683"},"user_tz":480},"id":"XoKW_GCNbUil","outputId":"8ec6174d-b24c-4656-8d0d-4e9a314e64e5"},"outputs":[{"name":"stdout","output_type":"stream","text":["/ressources/My Drive/ressources/BDF/DATASET/train ['1', '2', '3', '7', '6', '4', '5']\n","/ressources/My Drive/ressources/BDF/DATASET/test ['3', '7', '2', '4', '6', '1', '5']\n"]}],"source":["#je liste tous mes sous dossier du repertoir train :entrainement et test respectivement dans sous_dossier_train et sous_dossier_test\n","\n","principale_train= r\"/ressources/My Drive/ressources/BDF/DATASET/train\"\n","sous_dossier_train= []\n","sous_dossier_train = find_Class(principale_train)\n","\n","principale_test= r\"/ressources/My Drive/ressources/BDF/DATASET/test\"\n","sous_dossier_test= []\n","sous_dossier_test = find_Class(principale_test)\n","\n","\n","print(f\"{principale_train} {sous_dossier_train}\")\n","\n","\n","print(f\"{principale_test} {sous_dossier_test}\")\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":294285,"status":"ok","timestamp":1733294666919,"user":{"displayName":"Marien Manima","userId":"08622047204238479683"},"user_tz":480},"id":"fdoEFKnLp_aT","outputId":"586f9096-4cc9-41ec-8903-3730de5afb82"},"outputs":[{"name":"stdout","output_type":"stream","text":["/ressources/My Drive/ressources/BDF/DATASET/train/1\n","/ressources/My Drive/ressources/BDF/DATASET/train/2\n","/ressources/My Drive/ressources/BDF/DATASET/train/3\n","/ressources/My Drive/ressources/BDF/DATASET/train/7\n","/ressources/My Drive/ressources/BDF/DATASET/train/6\n","/ressources/My Drive/ressources/BDF/DATASET/train/4\n","/ressources/My Drive/ressources/BDF/DATASET/train/5\n","/ressources/My Drive/ressources/BDF/DATASET/test/3\n","/ressources/My Drive/ressources/BDF/DATASET/test/7\n","/ressources/My Drive/ressources/BDF/DATASET/test/2\n","/ressources/My Drive/ressources/BDF/DATASET/test/4\n","/ressources/My Drive/ressources/BDF/DATASET/test/6\n","/ressources/My Drive/ressources/BDF/DATASET/test/1\n","/ressources/My Drive/ressources/BDF/DATASET/test/5\n"]}],"source":["#convertion des images en liste pour la manipulation ici nous mettons tout dans la variable data\n","\n","emotions={\"1\":\"surprise\", \"2\":\"fear\", \"6\":\"angry\", \"7\":\"neutral\", \"5\":\"sad\", \"3\":\"disgust\", \"4\":\"happy\"}\n","data=[]\n","data= transformationImageEnTableau(principale_train,sous_dossier_train,data)\n","\n","data= transformationImageEnTableau(principale_test,sous_dossier_test,data)\n","\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":106,"output_embedded_package_id":"1nUEowUL_USacnz0ywavJGHbkfyrQQ0mZ"},"executionInfo":{"elapsed":34,"status":"error","timestamp":1733294737565,"user":{"displayName":"Marien Manima","userId":"08622047204238479683"},"user_tz":480},"id":"fYH1SrDhXgOD","outputId":"5dba1ea1-8633-43a0-ae09-214d9d1b5f2d"},"outputs":[],"source":["  def count_values(d):\n","    print(d)\n","    emotions={\"1\":\"surprise\", \"2\":\"fear\", \"6\":\"angry\", \"7\":\"neutral\", \"5\":\"sad\", \"3\":\"disgust\", \"4\":\"happy\"}\n","    count_value={}\n","    cont=0\n","    for key ,val in emotions.items():\n","        cont=0\n","        for value in d:\n","            if key== value[1]:\n","              cont=cont+1\n","        count_value[val]=cont\n","    return count_value\n","\n","\n","\n","    return value_counts\n","count_values(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qDk1w43bXS-w"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7sTzsgTShRbb"},"outputs":[],"source":["#melange des données\n","\n","random.shuffle(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Oz0N05lZhWOd"},"outputs":[],"source":["x=[]\n","y=[]\n","\n","for features,label in data:\n","    x.append(features)\n","    y.append(label)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4qUQztidhgTi"},"outputs":[],"source":["X= np.array(x)\n","Y=np.array(y)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1475,"status":"ok","timestamp":1732991860411,"user":{"displayName":"Marien Manima","userId":"08622047204238479683"},"user_tz":480},"id":"R9NH9I2ihmNN","outputId":"9c5ce6c8-3af8-45a8-cf09-ee5b700c011a"},"outputs":[{"data":{"text/plain":["(15429,)"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["X=X/255\n","X.shape\n","Y.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sdNPtqFBhsyI"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q-XwPFgHiAOj"},"outputs":[],"source":["model=Sequential()\n","model.add( Conv2D(64,(3,3),input_shape=X.shape[1:],activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","model.add( Conv2D(64,(3,3),activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add( Conv2D(32,(3,3),activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","\n","model.add(Flatten())\n","\n","model.add(Dense(7,activation='softmax'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JhWujm9miPd9"},"outputs":[],"source":["\n","model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n","checkpoint=ModelCheckpoint(r'fer.keras',\n","                          monitor='val_accuracy',\n","                          mode='max',\n","                          save_best_only=True,\n","                          verbose=1)\n","earlystop=EarlyStopping(monitor='val_accuracy',\n","                        mode='max',\n","                       min_delta=0.001,\n","                       patience=20,\n","                       verbose=1,\n","                       restore_best_weights=True)\n","\n","callbacks=[checkpoint,earlystop]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"KW9Q04QxiTxW","outputId":"5729966a-b6e2-4044-a43d-c163d75718d6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","362/362 [==============================] - ETA: 0s - loss: 1.3965 - accuracy: 0.4927\n","Epoch 1: val_accuracy improved from -inf to 0.63867, saving model to fer.keras\n","362/362 [==============================] - 222s 610ms/step - loss: 1.3965 - accuracy: 0.4927 - val_loss: 1.0386 - val_accuracy: 0.6387\n","Epoch 2/20\n","362/362 [==============================] - ETA: 0s - loss: 0.9856 - accuracy: 0.6546\n","Epoch 2: val_accuracy improved from 0.63867 to 0.68092, saving model to fer.keras\n","362/362 [==============================] - 214s 590ms/step - loss: 0.9856 - accuracy: 0.6546 - val_loss: 0.8958 - val_accuracy: 0.6809\n","Epoch 3/20\n","362/362 [==============================] - ETA: 0s - loss: 0.8234 - accuracy: 0.7133\n","Epoch 3: val_accuracy improved from 0.68092 to 0.69181, saving model to fer.keras\n","362/362 [==============================] - 216s 597ms/step - loss: 0.8234 - accuracy: 0.7133 - val_loss: 0.8817 - val_accuracy: 0.6918\n","Epoch 4/20\n","362/362 [==============================] - ETA: 0s - loss: 0.7366 - accuracy: 0.7444\n","Epoch 4: val_accuracy improved from 0.69181 to 0.71773, saving model to fer.keras\n","362/362 [==============================] - 213s 588ms/step - loss: 0.7366 - accuracy: 0.7444 - val_loss: 0.7927 - val_accuracy: 0.7177\n","Epoch 5/20\n","362/362 [==============================] - ETA: 0s - loss: 0.6563 - accuracy: 0.7747\n","Epoch 5: val_accuracy improved from 0.71773 to 0.72913, saving model to fer.keras\n","362/362 [==============================] - 209s 576ms/step - loss: 0.6563 - accuracy: 0.7747 - val_loss: 0.7939 - val_accuracy: 0.7291\n","Epoch 6/20\n","362/362 [==============================] - ETA: 0s - loss: 0.5986 - accuracy: 0.7876\n","Epoch 6: val_accuracy improved from 0.72913 to 0.74209, saving model to fer.keras\n","362/362 [==============================] - 209s 579ms/step - loss: 0.5986 - accuracy: 0.7876 - val_loss: 0.7408 - val_accuracy: 0.7421\n","Epoch 7/20\n","362/362 [==============================] - ETA: 0s - loss: 0.5322 - accuracy: 0.8177\n","Epoch 7: val_accuracy did not improve from 0.74209\n","362/362 [==============================] - 207s 571ms/step - loss: 0.5322 - accuracy: 0.8177 - val_loss: 0.8003 - val_accuracy: 0.7387\n","Epoch 8/20\n","362/362 [==============================] - ETA: 0s - loss: 0.4923 - accuracy: 0.8304\n","Epoch 8: val_accuracy improved from 0.74209 to 0.74469, saving model to fer.keras\n","362/362 [==============================] - 209s 578ms/step - loss: 0.4923 - accuracy: 0.8304 - val_loss: 0.7551 - val_accuracy: 0.7447\n","Epoch 9/20\n","362/362 [==============================] - ETA: 0s - loss: 0.4448 - accuracy: 0.8435\n","Epoch 9: val_accuracy did not improve from 0.74469\n","362/362 [==============================] - 204s 565ms/step - loss: 0.4448 - accuracy: 0.8435 - val_loss: 0.8138 - val_accuracy: 0.7426\n","Epoch 10/20\n","362/362 [==============================] - ETA: 0s - loss: 0.3974 - accuracy: 0.8596\n","Epoch 10: val_accuracy did not improve from 0.74469\n","362/362 [==============================] - 205s 567ms/step - loss: 0.3974 - accuracy: 0.8596 - val_loss: 0.8654 - val_accuracy: 0.7356\n","Epoch 11/20\n","362/362 [==============================] - ETA: 0s - loss: 0.3659 - accuracy: 0.8702\n","Epoch 11: val_accuracy did not improve from 0.74469\n","362/362 [==============================] - 205s 566ms/step - loss: 0.3659 - accuracy: 0.8702 - val_loss: 0.8902 - val_accuracy: 0.7369\n","Epoch 12/20\n","362/362 [==============================] - ETA: 0s - loss: 0.3343 - accuracy: 0.8793\n","Epoch 12: val_accuracy did not improve from 0.74469\n","362/362 [==============================] - 204s 564ms/step - loss: 0.3343 - accuracy: 0.8793 - val_loss: 0.9706 - val_accuracy: 0.7338\n","Epoch 13/20\n","362/362 [==============================] - ETA: 0s - loss: 0.2991 - accuracy: 0.8942\n","Epoch 13: val_accuracy did not improve from 0.74469\n","362/362 [==============================] - 205s 566ms/step - loss: 0.2991 - accuracy: 0.8942 - val_loss: 0.9761 - val_accuracy: 0.7201\n","Epoch 14/20\n","362/362 [==============================] - ETA: 0s - loss: 0.2734 - accuracy: 0.9020\n","Epoch 14: val_accuracy improved from 0.74469 to 0.74598, saving model to fer.keras\n","362/362 [==============================] - 208s 575ms/step - loss: 0.2734 - accuracy: 0.9020 - val_loss: 0.9801 - val_accuracy: 0.7460\n","Epoch 15/20\n","362/362 [==============================] - ETA: 0s - loss: 0.2429 - accuracy: 0.9141\n","Epoch 15: val_accuracy did not improve from 0.74598\n","362/362 [==============================] - 206s 568ms/step - loss: 0.2429 - accuracy: 0.9141 - val_loss: 1.0988 - val_accuracy: 0.7424\n","Epoch 16/20\n","362/362 [==============================] - ETA: 0s - loss: 0.2196 - accuracy: 0.9208\n","Epoch 16: val_accuracy did not improve from 0.74598\n","362/362 [==============================] - 207s 572ms/step - loss: 0.2196 - accuracy: 0.9208 - val_loss: 1.1545 - val_accuracy: 0.7255\n","Epoch 17/20\n","362/362 [==============================] - ETA: 0s - loss: 0.2032 - accuracy: 0.9262\n","Epoch 17: val_accuracy did not improve from 0.74598\n","362/362 [==============================] - 207s 573ms/step - loss: 0.2032 - accuracy: 0.9262 - val_loss: 1.1598 - val_accuracy: 0.7281\n","Epoch 18/20\n","362/362 [==============================] - ETA: 0s - loss: 0.1707 - accuracy: 0.9392\n","Epoch 18: val_accuracy did not improve from 0.74598\n","362/362 [==============================] - 206s 570ms/step - loss: 0.1707 - accuracy: 0.9392 - val_loss: 1.2870 - val_accuracy: 0.7377\n","Epoch 19/20\n","362/362 [==============================] - ETA: 0s - loss: 0.1656 - accuracy: 0.9405\n","Epoch 19: val_accuracy did not improve from 0.74598\n","362/362 [==============================] - 208s 575ms/step - loss: 0.1656 - accuracy: 0.9405 - val_loss: 1.3576 - val_accuracy: 0.7188\n","Epoch 20/20\n","362/362 [==============================] - ETA: 0s - loss: 0.1450 - accuracy: 0.9488\n","Epoch 20: val_accuracy did not improve from 0.74598\n","362/362 [==============================] - 207s 572ms/step - loss: 0.1450 - accuracy: 0.9488 - val_loss: 1.3605 - val_accuracy: 0.7250\n"]}],"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n","\n","history = model.fit(\n","    X_train, Y_train,\n","    epochs=20,\n","    validation_data=(X_test, Y_test),\n","    callbacks=callbacks\n",")\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":158},"executionInfo":{"elapsed":1504,"status":"error","timestamp":1733001227698,"user":{"displayName":"Marien Manima","userId":"08622047204238479683"},"user_tz":480},"id":"_f7z3Tptjc2v","outputId":"00eea220-2f53-4272-95f1-8a074f1be7a1"},"outputs":[{"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-1-dea33a34953c\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 1\u003e\u001b[0;34m()\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Loss: {loss}, Accuracy: {accuracy}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}],"source":["\n","\n","loss, accuracy = model.evaluate(X_train, Y_train)\n","print(f\"Loss: {loss}, Accuracy: {accuracy}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"bcRt7x-_lKrb","outputId":"68938658-21d0-4188-c95a-838dba00a944"},"outputs":[{"ename":"NameError","evalue":"name 'y_pred_classes' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-18-f97075e1287f\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 27\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Calcul de la matrice de confusion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 27\u001b[0;31m \u001b[0mconf_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'y_pred_classes' is not defined"]}],"source":["from tensorflow.keras.models import load_model\n","\n","model = load_model(\"fer.keras\")\n","X_test[0].shape\n","\"\"\"\n","val=traiterImage(\"/c.jpeg\")\n","\n","\n","\n","image = np.expand_dims(val\n",", axis=0)  # Ajoute la dimnsion batch\n","\n","\n","predictions = model.predict(image)\n","\n","print(f\"{predictions}\")\n","\n","y_pred = model.predict(X_test)  # Prédictions sous forme de probabilités\n","y_pred_classes = np.argmax(y_pred, axis=1)\n","\"\"\"\n","\n","\n","\n","from sklearn.metrics import confusion_matrix\n","\n","# Calcul de la matrice de confusion\n","conf_matrix = confusion_matrix(Y_test, y_pred_classes)\n","\n","\n","\n","\"\"\"\n","print(\"Matrice de confusion :\\n\", conf_matrix)\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Labels des classes (exemple pour 7 émotions)\n","class_names = [\"Colère\", \"Dégoût\", \"Peur\", \"Joie\", \"Tristesse\", \"Surprise\", \"Neutre\"]\n","\n","# Visualisation\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n","plt.xlabel('Prédictions')\n","plt.ylabel('Vérités')\n","plt.title('Matrice de confusion')\n","plt.show()\n","\"\"\"\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DwyQDrtf2Ctk"},"outputs":[],"source":["# import dependencies\n","from IPython.display import display, Javascript, Image\n","from google.colab.output import eval_js\n","from base64 import b64decode, b64encode\n","import cv2\n","import numpy as np\n","import PIL\n","import io\n","import html\n","import time\n","import tensorflow as tf\n","\n","# Importer les dépendances nécessaires\n","from IPython.display import display, Javascript, Image\n","from google.colab.output import eval_js\n","from base64 import b64decode\n","import cv2\n","import numpy as np\n","from tensorflow.keras.models import load_model\n","import PIL.Image\n","import io\n","\n","# Charger le modèle\n","model = load_model(\"fer.keras\")  # Remplace \"fer.keras\" par le chemin de ton modèle\n","emotion_labels = [\"Neutral\", \"Happy\", \"Sad\", \"Surprise\", \"Fear\", \"Angry\", \"Disgust\"]\n","\n","# Charger le cascade Haar pour la détection de visage\n","face_cascade = cv2.CascadeClassifier(cv2.samples.findFile(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'))\n","\n","# Fonction pour convertir les données JS en image OpenCV\n","def js_to_image(js_data):\n","    img_data = b64decode(js_data.split(',')[1])\n","    img = PIL.Image.open(io.BytesIO(img_data))\n","    return np.array(img)\n","\n","# Fonction pour dessiner des rectangles autour des visages détectés\n","def bbox_to_bytes(bbox_array):\n","    bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n","    iobuf = io.BytesIO()\n","    bbox_PIL.save(iobuf, format='png')\n","    bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n","    return bbox_bytes\n","\n","# JavaScript pour capturer la vidéo\n","def video_stream():\n","    js = Javascript('''\n","    var video;\n","    var div = null;\n","    var stream;\n","    var captureCanvas;\n","    var imgElement;\n","\n","    var pendingResolve = null;\n","    var shutdown = false;\n","\n","    function removeDom() {\n","       stream.getVideoTracks()[0].stop();\n","       video.remove();\n","       div.remove();\n","       video = null;\n","       div = null;\n","       stream = null;\n","       imgElement = null;\n","       captureCanvas = null;\n","    }\n","\n","    async function createDom() {\n","      if (div !== null) {\n","        return stream;\n","      }\n","\n","      div = document.createElement('div');\n","      div.style.border = '2px solid black';\n","      div.style.padding = '3px';\n","      div.style.width = '100%';\n","      div.style.maxWidth = '600px';\n","      document.body.appendChild(div);\n","\n","      video = document.createElement('video');\n","      video.style.display = 'block';\n","      video.width = div.clientWidth - 6;\n","      video.setAttribute('playsinline', '');\n","      video.onclick = () =\u003e { shutdown = true; };\n","      stream = await navigator.mediaDevices.getUserMedia(\n","          {video: { facingMode: \"user\"}});\n","      div.appendChild(video);\n","\n","      imgElement = document.createElement('img');\n","      imgElement.style.position = 'absolute';\n","      imgElement.style.zIndex = 1;\n","      imgElement.onclick = () =\u003e { shutdown = true; };\n","      div.appendChild(imgElement);\n","\n","      video.srcObject = stream;\n","      await video.play();\n","\n","      captureCanvas = document.createElement('canvas');\n","      captureCanvas.width = 640; //video.videoWidth;\n","      captureCanvas.height = 480; //video.videoHeight;\n","\n","      return stream;\n","    }\n","    async function stream_frame() {\n","      if (shutdown) {\n","        removeDom();\n","        shutdown = false;\n","        return '';\n","      }\n","\n","      stream = await createDom();\n","      captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n","      return captureCanvas.toDataURL('image/jpeg', 0.8);\n","    }\n","    ''')\n","    display(js)\n","\n","# Fonction pour capturer un cadre\n","def video_frame():\n","    data = eval_js('stream_frame()')\n","    return data\n","\n","# Lancer le flux vidéo\n","video_stream()\n","\n","# Prédiction en temps réel\n","while True:\n","    js_reply = video_frame()\n","    if not js_reply:\n","        break\n","\n","    # Convertir les données JS en image OpenCV\n","    img = js_to_image(js_reply)\n","\n","    # Détection des visages (grayscale pour Haar Cascade)\n","    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n","    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n","\n","    # Superposition transparente\n","    bbox_array = np.zeros([480, 640, 4], dtype=np.uint8)\n","\n","    for (x, y, w, h) in faces:\n","        # Extraire et prétraiter le visage en couleur\n","        face = img[y:y+h, x:x+w]  # Garder les 3 canaux couleur\n","        face = cv2.resize(face, (48, 48))  # Adapter à la taille du modèle\n","        face = face / 255.0  # Normaliser\n","        face = np.expand_dims(face, axis=0)  # Ajouter une dimension batch\n","\n","        # Prédiction\n","        predictions = model.predict(face)\n","        emotion_index = np.argmax(predictions)\n","        emotion = emotion_labels[emotion_index]\n","        confidence = np.max(predictions) * 100\n","\n","        # Dessiner le rectangle autour du visage\n","        cv2.rectangle(bbox_array, (x, y), (x+w, y+h), (255, 0, 0), 2)\n","\n","        # Ajouter l'émotion prédite\n","        cv2.putText(\n","            bbox_array, f\"{emotion} ({confidence:.1f}%)\",\n","            (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2\n","        )\n","\n","    # Ajouter un canal alpha pour la superposition\n","    bbox_array[:, :, 3] = (bbox_array.max(axis=2) \u003e 0).astype(int) * 255\n","\n","    # Convertir en base64 pour afficher l'image\n","    bbox = bbox_to_bytes(bbox_array)\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9KlcyxEriZ8x"},"outputs":[],"source":["model.summary()"]}],"metadata":{"accelerator":"TPU","colab":{"authorship_tag":"ABX9TyMw0S0rwVgud8SOaexrIQFp","gpuType":"V28","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}